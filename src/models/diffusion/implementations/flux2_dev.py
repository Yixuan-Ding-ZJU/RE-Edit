"""
Flux.2-dev diffusion model implementation
Flux.2-dev å›¾åƒç¼–è¾‘æ¨¡å‹å®ç°ï¼ˆæ”¯æŒå¤šGPUå¹¶è¡Œ - å¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰

åŸºäº black-forest-labs/FLUX.2-dev
ä½¿ç”¨ enable_model_cpu_offload() ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨

å¤šè¿›ç¨‹æ¶æ„ï¼š
- æ¯ä¸ªGPUå¯¹åº”ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹
- è¿›ç¨‹é—´å®Œå…¨éš”ç¦»ï¼Œé¿å…GILå’Œèµ„æºç«äº‰
- ä½¿ç”¨Queueè¿›è¡Œè¿›ç¨‹é—´é€šä¿¡
"""

import multiprocessing as mp
import torch
from PIL import Image
from typing import List, Dict, Any
from tqdm import tqdm
import base64
from io import BytesIO
import sys
import threading

from ..base_diffusion import BaseDiffusionModel
from ....utils import setup_logger

# å¿…é¡»è®¾ç½®ï¼Œå¦åˆ™å¤šè¿›ç¨‹ä¼šå‡ºé”™
mp.set_start_method('spawn', force=True)


def _load_model_in_process(gpu_id: int, model_name: str, config: Dict[str, Any]):
    """
    åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­åŠ è½½æ¨¡å‹
    
    Args:
        gpu_id: GPU ID
        model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
        config: æ¨¡å‹é…ç½®å‚æ•°
    
    Returns:
        pipelineå¯¹è±¡
    """
    print(f"[GPU {gpu_id}] ğŸ”„ Loading Flux.2-dev model...")
    try:
        from diffusers import Flux2Pipeline
        
        # è®¾ç½®å½“å‰è®¾å¤‡
        torch.cuda.set_device(gpu_id)
        
        # æ¸…ç©ºGPUç¼“å­˜
        print(f"[GPU {gpu_id}] ğŸ§¹ Clearing GPU cache...")
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        
        # è§£ædtype
        dtype = config.get("dtype", "bfloat16")
        if dtype == "bfloat16":
            torch_dtype = torch.bfloat16
        elif dtype == "float16":
            torch_dtype = torch.float16
        else:
            torch_dtype = torch.float32
        
        # åŠ è½½æ¨¡å‹
        print(f"[GPU {gpu_id}] ğŸ”¹ Loading Flux.2-dev pipeline...")
        pipeline = Flux2Pipeline.from_pretrained(
            model_name,
            torch_dtype=torch_dtype,
        )
        
        # ä½¿ç”¨ enable_model_cpu_offload() ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
        use_cpu_offload = config.get("use_cpu_offload", True)
        if use_cpu_offload:
            print(f"[GPU {gpu_id}] ğŸ”¹ Enabling model CPU offload for GPU {gpu_id}...")
            pipeline.enable_model_cpu_offload(gpu_id=gpu_id)
        else:
            # å¦‚æœä¸ä½¿ç”¨CPU offloadï¼Œç›´æ¥ç§»åŠ¨åˆ°ç›®æ ‡GPU
            print(f"[GPU {gpu_id}] ğŸ”¹ Moving model to cuda:{gpu_id}...")
            pipeline.to(f"cuda:{gpu_id}")
        
        # ç¦ç”¨è¿›åº¦æ¡
        if config.get("disable_progress_bar", True):
            pipeline.set_progress_bar_config(disable=True)
        
        print(f"[GPU {gpu_id}] âœ… Model loaded successfully")
        return pipeline
        
    except Exception as e:
        print(f"[GPU {gpu_id}] âŒ Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return None


def _image_to_base64(image: Image.Image) -> str:
    """å°†PIL Imageè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
    buffer = BytesIO()
    image.save(buffer, format='PNG')
    return base64.b64encode(buffer.getvalue()).decode('utf-8')


def _base64_to_image(b64_str: str) -> Image.Image:
    """å°†base64å­—ç¬¦ä¸²è½¬æ¢ä¸ºPIL Image"""
    image_data = base64.b64decode(b64_str)
    return Image.open(BytesIO(image_data))


def _process_worker(gpu_id: int, model_name: str, config: Dict[str, Any], 
                    task_queue: mp.Queue, result_queue: mp.Queue):
    """
    è¿›ç¨‹å·¥ä½œå‡½æ•°ï¼šåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­å¤„ç†å›¾åƒç¼–è¾‘ä»»åŠ¡
    
    Args:
        gpu_id: GPU ID
        model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
        config: æ¨¡å‹é…ç½®å‚æ•°
        task_queue: ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ¥æ”¶ä»»åŠ¡ï¼‰
        result_queue: ç»“æœé˜Ÿåˆ—ï¼ˆå‘é€ç»“æœï¼‰
    """
    try:
        # åŠ è½½æ¨¡å‹
        pipeline = _load_model_in_process(gpu_id, model_name, config)
        if pipeline is None:
            print(f"[GPU {gpu_id}] âŒ Failed to load model, exiting...")
            return
        
        # æå–é…ç½®å‚æ•°
        num_inference_steps = config.get("num_inference_steps", 50)
        guidance_scale = config.get("guidance_scale", 4.0)
        seed = config.get("seed", 0)
        
        print(f"[GPU {gpu_id}] âœ… Worker ready, waiting for tasks...")
        
        # å¤„ç†ä»»åŠ¡å¾ªç¯
        while True:
            # ä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡
            task = task_queue.get()
            
            # æ£€æŸ¥ç»“æŸä¿¡å·
            if task is None:
                print(f"[GPU {gpu_id}] ğŸ›‘ Received stop signal, exiting...")
                break
            
            task_id, image_b64, instruction, current_seed, kwargs = task
            
            try:
                # è§£ç å›¾åƒ
                image = _base64_to_image(image_b64)
                
                # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                
                # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è®¾å¤‡
                torch.cuda.set_device(gpu_id)
                
                # å‡†å¤‡å‚æ•°
                num_steps = kwargs.get("num_inference_steps", num_inference_steps)
                guidance = kwargs.get("guidance_scale", guidance_scale)
                use_seed = current_seed if current_seed is not None else seed
                show_progress = kwargs.get("show_progress", True)  # é»˜è®¤æ˜¾ç¤ºè¿›åº¦æ¡
                
                # å‡†å¤‡pipelineè¾“å…¥
                pipeline_inputs = {
                    "prompt": instruction,
                    "image": [image],
                    "generator": torch.Generator(device=f"cuda:{gpu_id}").manual_seed(use_seed),
                    "guidance_scale": guidance,
                    "num_inference_steps": num_steps,
                }
                
                # æ·»åŠ å»å™ªè¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                pbar = None
                if show_progress:
                    # ä¸ºæ¯ä¸ªGPUè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„è¿›åº¦æ¡
                    # åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸‹ï¼Œæ¯ä¸ªè¿›ç¨‹ä¼šç‹¬ç«‹æ˜¾ç¤ºè‡ªå·±çš„è¿›åº¦æ¡
                    # ä½¿ç”¨GPU IDå’ŒTask IDä½œä¸ºæ ‡è¯†ï¼Œä¾¿äºåŒºåˆ†ä¸åŒè¿›ç¨‹çš„è¿›åº¦
                    pbar = tqdm(
                        total=num_steps,
                        desc=f"[GPU {gpu_id}] Task {task_id} Denoising",
                        unit="step",
                        leave=False,  # å®Œæˆåæ¸…é™¤ï¼Œé¿å…è¾“å‡ºæ··ä¹±
                        file=sys.stdout,
                        ncols=100,  # é™åˆ¶å®½åº¦ï¼Œé¿å…å¤šè¿›ç¨‹è¾“å‡ºæ—¶æ··ä¹±
                        dynamic_ncols=False,  # å›ºå®šå®½åº¦
                        bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
                    )
                    
                    def callback(pipe, step_index, timestep, callback_kwargs):
                        if pbar is not None:
                            pbar.update(1)
                        return callback_kwargs
                    
                    pipeline_inputs["callback_on_step_end"] = callback
                
                # æ‰§è¡Œæ¨ç†
                try:
                    with torch.inference_mode():
                        output = pipeline(**pipeline_inputs)
                        edited_image = output.images[0]
                finally:
                    # å…³é—­è¿›åº¦æ¡
                    if pbar is not None:
                        pbar.close()
                
                # ç¼–ç ç»“æœå›¾åƒ
                result_b64 = _image_to_base64(edited_image)
                
                # å‘é€ç»“æœ
                result_queue.put((task_id, True, result_b64, None))
                
            except Exception as e:
                print(f"[GPU {gpu_id}] âŒ Error processing task {task_id}: {e}")
                import traceback
                traceback.print_exc()
                # å‘é€é”™è¯¯ç»“æœ
                result_queue.put((task_id, False, None, str(e)))
            
            # æ¸…ç†GPUç¼“å­˜
            torch.cuda.empty_cache()
        
        print(f"[GPU {gpu_id}] ğŸ‘‹ Worker exiting...")
        
    except Exception as e:
        print(f"[GPU {gpu_id}] âŒ Fatal error in worker: {e}")
        import traceback
        traceback.print_exc()
    


class Flux2DevModel(BaseDiffusionModel):
    """
    Flux.2-dev å›¾åƒç¼–è¾‘æ¨¡å‹ï¼ˆå¤šGPUå¹¶è¡Œ - å¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
    
    ä½¿ç”¨multiprocessingå®ç°æ•°æ®å¹¶è¡Œï¼š
    - æ¯ä¸ªGPUå¯¹åº”ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹
    - æ¯ä¸ªè¿›ç¨‹åŠ è½½ä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬ï¼ˆä½¿ç”¨CPU offloadä¼˜åŒ–æ˜¾å­˜ï¼‰
    - ä»»åŠ¡æŒ‰è½®è¯¢æ–¹å¼åˆ†é…åˆ°å„ä¸ªGPUè¿›ç¨‹
    - æ‰€æœ‰GPUè¿›ç¨‹å¹¶è¡Œå¤„ç†ä¸åŒçš„å›¾åƒ
    
    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨ enable_model_cpu_offload() è‡ªåŠ¨ç®¡ç†æ˜¾å­˜
    - æ”¯æŒæ‰¹æ¬¡åŒæ­¥ï¼Œç¡®ä¿GPUé—´è¿›åº¦ä¸€è‡´
    - è¿›ç¨‹é—´å®Œå…¨éš”ç¦»ï¼Œé¿å…GILå’Œèµ„æºç«äº‰
    """
    
    def _initialize(self):
        """åˆå§‹åŒ–å¤šGPUæ¨¡å‹ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰"""
        # è·å–é…ç½®
        self.model_name = self.config.get("model_name", "black-forest-labs/FLUX.2-dev")
        device_ids = self.config.get("device_ids", None)
        
        # ç¡®å®šä½¿ç”¨å“ªäº›GPU
        if device_ids is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
            self.num_gpus = torch.cuda.device_count()
            self.device_ids = list(range(self.num_gpus))
        else:
            self.device_ids = device_ids
            self.num_gpus = len(device_ids)
        
        print(f"[Flux2Dev] æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªGPU")
        print(f"[Flux2Dev] å°†ä½¿ç”¨ {self.num_gpus} ä¸ªGPU: {self.device_ids}")
        print(f"[Flux2Dev] ä½¿ç”¨å¤šè¿›ç¨‹æ¶æ„ï¼ˆæ¯ä¸ªGPUä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹ï¼‰\n")
        
        # åˆ›å»ºè¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—
        self.task_queues = [mp.Queue() for _ in range(self.num_gpus)]
        self.result_queue = mp.Queue()
        
        # ç”¨äºè¿­ä»£refinementæ¨¡å¼çš„ç»“æœåˆ†å‘ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        # key: task_id, value: (result_data, event)
        self._pending_results = {}  # å­˜å‚¨å¾…åˆ†å‘çš„ç»“æœ
        self._result_lock = threading.Lock()  # ä¿æŠ¤pending_resultsçš„é”
        self._result_dispatcher_thread = None  # ç»“æœåˆ†å‘çº¿ç¨‹
        self._result_dispatcher_started = False  # æ ‡è®°ResultDispatcheræ˜¯å¦å·²å¯åŠ¨
        
        # å¯åŠ¨å·¥ä½œè¿›ç¨‹
        self.processes = []
        print("=" * 70)
        print("ğŸš€ Starting Worker Processes (Flux.2-dev)")
        print("=" * 70)
        print(f"Starting {self.num_gpus} worker processes...")
        print("(Each process will load model independently)")
        print()
        
        for idx, gpu_id in enumerate(self.device_ids):
            print(f"[{idx+1}/{self.num_gpus}] Starting process for GPU {gpu_id}...")
            
            p = mp.Process(
                target=_process_worker,
                args=(
                    gpu_id,
                    self.model_name,
                    self.config,
                    self.task_queues[idx],
                    self.result_queue
                ),
                name=f"GPU-{gpu_id}"
            )
            p.start()
            self.processes.append((gpu_id, p))
            print(f"  âœ… GPU {gpu_id}: Process started (PID: {p.pid})\n")
        
        print(f"âœ… Successfully started {len(self.processes)} worker processes")
        print(f"  âš¡ All processes are loading models independently")
        print("=" * 70)
        print()
    
    def _start_result_dispatcher(self):
        """
        å¯åŠ¨ç»“æœåˆ†å‘çº¿ç¨‹ï¼ˆä»…åœ¨è¿­ä»£refinementæ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
        
        è¯¥çº¿ç¨‹ä»result_queueä¸­è¯»å–ç»“æœï¼Œå¹¶å°†å…¶åˆ†å‘åˆ°å¯¹åº”çš„ç­‰å¾…çº¿ç¨‹
        ç”¨äºæ”¯æŒè¿­ä»£refinementæ¨¡å¼ä¸‹çš„å¤šçº¿ç¨‹å¹¶å‘
        """
        # å¦‚æœå·²ç»å¯åŠ¨ï¼Œç›´æ¥è¿”å›
        if self._result_dispatcher_started:
            print(f"[Flux2Dev] ResultDispatcher already started, skipping")
            return
        
        def dispatcher():
            """ç»“æœåˆ†å‘å™¨ï¼šä»result_queueè¯»å–ç»“æœå¹¶åˆ†å‘åˆ°å¯¹åº”çš„ç­‰å¾…çº¿ç¨‹ï¼ˆä»…ç”¨äºè¿­ä»£refinementæ¨¡å¼ï¼‰"""
            print(f"[Flux2Dev] [ResultDispatcher] Thread started")
            try:
                while True:
                    try:
                        # ä»å…±äº«ç»“æœé˜Ÿåˆ—è¯»å–ç»“æœ
                        result_data = self.result_queue.get()
                        if result_data is None:  # é€€å‡ºä¿¡å·
                            print(f"[Flux2Dev] [ResultDispatcher] Received exit signal, stopping...")
                            break
                        
                        task_id, success, result_b64, error = result_data
                        
                        # å°†ç»“æœå­˜å‚¨åˆ°pending_resultsï¼Œå¹¶é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
                        # æ³¨æ„ï¼šResultDispatcheråªåœ¨è¿­ä»£æ¨¡å¼ä¸‹è¿è¡Œï¼Œæ‰€ä»¥æ‰€æœ‰ç»“æœéƒ½åº”è¯¥åœ¨_pending_resultsä¸­
                        with self._result_lock:
                            if task_id in self._pending_results:
                                # æ‰¾åˆ°ç­‰å¾…è¯¥ç»“æœçš„çº¿ç¨‹ï¼ˆè¿­ä»£refinementæ¨¡å¼ï¼‰
                                event, result_container = self._pending_results[task_id]
                                result_container['data'] = (success, result_b64, error)
                                event.set()  # é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
                            else:
                                # è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼ˆå› ä¸ºResultDispatcheråªåœ¨è¿­ä»£æ¨¡å¼ä¸‹è¿è¡Œï¼‰
                                # å¦‚æœå‘ç”Ÿäº†ï¼Œè¯´æ˜æœ‰bugï¼Œè®°å½•è­¦å‘Šä½†ä¸å¤„ç†ï¼ˆè®©batch_editè‡ªå·±å¤„ç†ï¼‰
                                print(f"âš ï¸  [Flux2Dev] [ResultDispatcher] Received result for task {task_id} but no waiting thread found (this should not happen in iterative mode)")
                    
                    except Exception as e:
                        print(f"âŒ [Flux2Dev] [ResultDispatcher] Error in dispatcher loop: {e}")
                        import traceback
                        traceback.print_exc()
                        # ç»§ç»­è¿è¡Œï¼Œä¸è¦å› ä¸ºå•ä¸ªé”™è¯¯è€Œåœæ­¢
            except Exception as e:
                print(f"âŒ [Flux2Dev] [ResultDispatcher] Fatal error: {e}")
                import traceback
                traceback.print_exc()
            finally:
                print(f"[Flux2Dev] [ResultDispatcher] Thread stopped")
        
        self._result_dispatcher_thread = threading.Thread(target=dispatcher, daemon=True, name="ResultDispatcher")
        self._result_dispatcher_thread.start()
        self._result_dispatcher_started = True
        print(f"[Flux2Dev] ResultDispatcher thread started (thread_id: {self._result_dispatcher_thread.ident})")
    
    def _stop_result_dispatcher(self):
        """åœæ­¢ç»“æœåˆ†å‘çº¿ç¨‹"""
        if not self._result_dispatcher_started:
            return
        
        if self._result_dispatcher_thread and self._result_dispatcher_thread.is_alive():
            print(f"[Flux2Dev] Stopping ResultDispatcher thread...")
            # å‘é€é€€å‡ºä¿¡å·
            try:
                self.result_queue.put(None)
            except Exception as e:
                print(f"[Flux2Dev] Warning: Failed to send exit signal to ResultDispatcher: {e}")
            
            # ç­‰å¾…çº¿ç¨‹é€€å‡º
            self._result_dispatcher_thread.join(timeout=2)
            if self._result_dispatcher_thread.is_alive():
                print(f"[Flux2Dev] Warning: ResultDispatcher thread did not stop within timeout")
            else:
                print(f"[Flux2Dev] ResultDispatcher thread stopped successfully")
        
        self._result_dispatcher_thread = None
        self._result_dispatcher_started = False
    
    def edit_image(self, original_image: Image.Image, 
                   edit_instruction: str,
                   **kwargs) -> Image.Image:
        """
        ç¼–è¾‘å•å¼ å›¾åƒï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªGPUè¿›ç¨‹ï¼‰
        
        Args:
            original_image: åŸå§‹PILå›¾åƒ
            edit_instruction: ç¼–è¾‘æŒ‡ä»¤
            **kwargs: å…¶ä»–å‚æ•°
                - target_gpu_id: æŒ‡å®šç›®æ ‡GPU IDï¼ˆç”¨äºè¿­ä»£refinementæ¨¡å¼ï¼‰
                - enable_batch_sync: æ˜¯å¦å¯ç”¨æ‰¹æ¬¡åŒæ­¥ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            ç¼–è¾‘åçš„PILå›¾åƒ
        """
        # å¦‚æœæŒ‡å®šäº†target_gpu_idï¼Œç›´æ¥ä½¿ç”¨è¯¥GPUï¼ˆç”¨äºè¿­ä»£refinementæ¨¡å¼ï¼‰
        target_gpu_id = kwargs.pop("target_gpu_id", None)
        if target_gpu_id is not None:
            return self._edit_image_on_specific_gpu(original_image, edit_instruction, target_gpu_id, **kwargs)
        
        # å•å¼ å›¾åƒä½¿ç”¨ç¬¬ä¸€ä¸ªGPUè¿›ç¨‹ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
        results = self.batch_edit([original_image], [edit_instruction], **kwargs)
        return results[0]
    
    def _edit_image_on_specific_gpu(self, original_image: Image.Image, edit_instruction: str, 
                                     target_gpu_id: int, **kwargs) -> Image.Image:
        """
        åœ¨æŒ‡å®šGPUä¸Šç¼–è¾‘å•å¼ å›¾åƒï¼ˆç”¨äºè¿­ä»£refinementæ¨¡å¼ï¼Œé¿å…batch_syncï¼‰
        
        Args:
            original_image: åŸå§‹PILå›¾åƒ
            edit_instruction: ç¼–è¾‘æŒ‡ä»¤æ–‡æœ¬
            target_gpu_id: ç›®æ ‡GPU ID
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç¼–è¾‘åçš„PILå›¾åƒ
        """
        # ç¡®ä¿ResultDispatcherå·²å¯åŠ¨ï¼ˆè¿­ä»£æ¨¡å¼éœ€è¦ï¼‰
        if not self._result_dispatcher_started:
            self._start_result_dispatcher()
        
        # éªŒè¯ResultDispatcherçº¿ç¨‹ç¡®å®åœ¨è¿è¡Œ
        if not (self._result_dispatcher_thread and self._result_dispatcher_thread.is_alive()):
            raise RuntimeError(f"ResultDispatcher thread is not running! This is required for iterative refinement mode.")
        
        # æ‰¾åˆ°target_gpu_idå¯¹åº”çš„é˜Ÿåˆ—ç´¢å¼•
        if target_gpu_id not in self.device_ids:
            raise ValueError(f"Target GPU {target_gpu_id} not in device_ids {self.device_ids}")
        
        gpu_idx = self.device_ids.index(target_gpu_id)
        
        # ç”Ÿæˆå”¯ä¸€çš„ä»»åŠ¡IDï¼ˆä½¿ç”¨æ—¶é—´æˆ³+éšæœºæ•°+GPU IDé¿å…å†²çªï¼‰
        import time
        import random
        # ä½¿ç”¨å¾®ç§’æ—¶é—´æˆ³ + GPU ID + éšæœºæ•°ï¼Œç¡®ä¿å…¨å±€å”¯ä¸€
        task_id = int(time.time() * 1000000) + target_gpu_id * 10000 + random.randint(0, 9999)
        
        # å‡†å¤‡å‚æ•°
        base_seed = kwargs.get("seed", self.config.get("seed", 0))
        current_seed = base_seed + task_id
        
        # ç¼–ç å›¾åƒ
        image_b64 = _image_to_base64(original_image)
        
        # åˆ›å»ºç­‰å¾…äº‹ä»¶å’Œç»“æœå®¹å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        result_event = threading.Event()
        result_container = {'data': None}
        
        # æ³¨å†Œç­‰å¾…è¯¥ä»»åŠ¡çš„ç»“æœ
        with self._result_lock:
            self._pending_results[task_id] = (result_event, result_container)
        
        try:
            # å‘é€ä»»åŠ¡åˆ°æŒ‡å®šçš„GPUé˜Ÿåˆ—
            task = (task_id, image_b64, edit_instruction, current_seed, kwargs)
            self.task_queues[gpu_idx].put(task)
            
            # ç­‰å¾…ç»“æœï¼ˆä½¿ç”¨äº‹ä»¶æœºåˆ¶ï¼Œé¿å…ä»å…±äº«é˜Ÿåˆ—é”™è¯¯è¯»å–ï¼‰
            if result_event.wait(timeout=300):  # 5åˆ†é’Ÿè¶…æ—¶
                # è·å–ç»“æœ
                with self._result_lock:
                    if task_id in self._pending_results:
                        del self._pending_results[task_id]
                    success, result_b64, error = result_container['data']
                
                if success:
                    return _base64_to_image(result_b64)
                else:
                    raise RuntimeError(f"Error editing image on GPU {target_gpu_id}: {error}")
            else:
                raise RuntimeError(f"Timeout waiting for result from GPU {target_gpu_id} (task_id: {task_id})")
        except Exception as e:
            # æ¸…ç†pending_results
            with self._result_lock:
                if task_id in self._pending_results:
                    del self._pending_results[task_id]
            raise RuntimeError(f"Error receiving result from GPU {target_gpu_id}: {e}")
    
    def batch_edit(self, images: List[Image.Image],
                   instructions: List[str],
                   **kwargs) -> List[Image.Image]:
        """
        å¤šGPUå¹¶è¡Œæ‰¹é‡ç¼–è¾‘å›¾åƒï¼ˆå¸¦æ‰¹æ¬¡åŒæ­¥ï¼‰
        
        å®ç°æ‰¹æ¬¡åŒæ­¥æœºåˆ¶ï¼š
        - å°†ä»»åŠ¡åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹å¤§å° = GPUæ•°é‡
        - æ¯æ‰¹ä»»åŠ¡æäº¤åï¼Œç­‰å¾…æ‰€æœ‰GPUå®Œæˆ
        - å†æäº¤ä¸‹ä¸€æ‰¹ï¼Œç¡®ä¿GPUä¹‹é—´ä¿æŒåŒæ­¥
        
        Args:
            images: åŸå§‹å›¾åƒåˆ—è¡¨
            instructions: ç¼–è¾‘æŒ‡ä»¤åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
                - enable_batch_sync: æ˜¯å¦å¯ç”¨æ‰¹æ¬¡åŒæ­¥ï¼ˆé»˜è®¤Trueï¼‰
                - num_inference_steps: æ¨ç†æ­¥æ•°
                - guidance_scale: Guidance scale
                - negative_prompt: è´Ÿé¢æç¤ºè¯
            
        Returns:
            ç¼–è¾‘åçš„å›¾åƒåˆ—è¡¨
        """
        # ç¡®ä¿ResultDispatcheræœªå¯åŠ¨ï¼ˆbatch_editæ¨¡å¼ä¸éœ€è¦ï¼Œç›´æ¥ä½¿ç”¨é˜Ÿåˆ—ï¼‰
        if self._result_dispatcher_started:
            self._stop_result_dispatcher()
        if len(images) != len(instructions):
            raise ValueError("Number of images must match number of instructions")
        
        n = len(images)
        num_gpus = self.num_gpus  # ä½¿ç”¨è¿›ç¨‹æ•°é‡è€Œä¸æ˜¯workersæ•°é‡
        enable_sync = kwargs.pop("enable_batch_sync", True)  # é»˜è®¤å¯ç”¨æ‰¹æ¬¡åŒæ­¥
        
        print(f"\n[Flux2Dev] Starting batch edit: {n} images on {num_gpus} GPUs")
        print(f"  ğŸ”„ Batch synchronization: {'ENABLED âœ…' if enable_sync else 'DISABLED âš ï¸'}")
        
        # é¢„å…ˆåˆ†é…ä»»åŠ¡å¹¶æ˜¾ç¤º
        print("=" * 70)
        print("ğŸ“‹ Task Assignment:")
        print("=" * 70)
        from collections import defaultdict
        gpu_assignments = defaultdict(list)
        
        for idx in range(n):
            gpu_id = self.device_ids[idx % num_gpus]
            gpu_assignments[gpu_id].append(idx)
        
        for gpu_id in sorted(gpu_assignments.keys()):
            assigned = gpu_assignments[gpu_id]
            print(f"  GPU {gpu_id}: {len(assigned)} images")
            preview = ", ".join(map(str, assigned[:5]))
            if len(assigned) > 5:
                preview += f", ... +{len(assigned) - 5} more"
            print(f"           â†’ [{preview}]")
        
        print("=" * 70)
        print()
        
        # ç»“æœåˆ—è¡¨ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
        results = [None] * n
        
        # è·å–åŸºç¡€seed
        base_seed = kwargs.get("seed", self.config.get("seed", 0))
        
        if enable_sync:
            # æ‰¹æ¬¡åŒæ­¥æ¨¡å¼ï¼šæ¯æ‰¹num_gpusä¸ªä»»åŠ¡ï¼Œæ‰¹æ¬¡é—´åŒæ­¥
            results = self._batch_edit_with_sync(
                images, instructions, n, num_gpus, base_seed, **kwargs
            )
        else:
            # åŸå§‹æ¨¡å¼ï¼šä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå‘åå…¼å®¹ï¼‰
            results = self._batch_edit_no_sync(
                images, instructions, n, num_gpus, base_seed, **kwargs
            )
        
        print(f"âœ… Batch edit completed: {n} images\n")
        return results
    
    def _batch_edit_with_sync(self, images, instructions, n, num_gpus, base_seed, **kwargs):
        """
        æ‰¹æ¬¡åŒæ­¥æ¨¡å¼ï¼šç¡®ä¿æ¯æ‰¹æ‰€æœ‰GPUå®Œæˆåå†å¼€å§‹ä¸‹ä¸€æ‰¹ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
        """
        results = [None] * n
        
        # è®¡ç®—æ‰¹æ¬¡æ•°
        num_batches = (n + num_gpus - 1) // num_gpus
        
        print(f"ğŸ”„ Batch synchronization mode (multiprocess):")
        print(f"   - Total batches: {num_batches}")
        print(f"   - Batch size: {num_gpus} (one task per GPU process)")
        print(f"   - All GPU processes will stay synchronized at batch boundaries\n")
        
        # æ€»è¿›åº¦æ¡
        with tqdm(total=n, desc="[SYNC] Editing images", unit="img") as pbar:
            # é€æ‰¹å¤„ç†
            for batch_idx in range(num_batches):
                batch_start = batch_idx * num_gpus
                batch_end = min(batch_start + num_gpus, n)
                batch_size = batch_end - batch_start
                
                # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡
                task_indices = []
                for i in range(batch_start, batch_end):
                    # ä½¿ç”¨å…¨å±€è½®è¯¢åˆ†é…ï¼ši % num_gpus ç¡®ä¿æ‰€æœ‰ä»»åŠ¡æŒ‰é¡ºåºè½®è¯¢åˆ†é…åˆ°ä¸åŒGPU
                    gpu_idx = i % num_gpus
                    current_seed = base_seed + i
                    
                    # ç¼–ç å›¾åƒ
                    image_b64 = _image_to_base64(images[i])
                    
                    # å‘é€ä»»åŠ¡åˆ°å¯¹åº”çš„GPUè¿›ç¨‹
                    task = (i, image_b64, instructions[i], current_seed, kwargs)
                    self.task_queues[gpu_idx].put(task)
                    task_indices.append(i)
                
                # ç­‰å¾…å½“å‰æ‰¹æ¬¡æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆåŒæ­¥ç‚¹ï¼‰
                # ä½¿ç”¨å­—å…¸è·Ÿè¸ªå½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡ï¼Œç¡®ä¿åªæ”¶é›†å½“å‰æ‰¹æ¬¡çš„ç»“æœ
                batch_results = {}
                expected_task_ids = set(task_indices)
                
                # ç­‰å¾…ç›´åˆ°æ”¶é›†åˆ°å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ç»“æœ
                # è¿™æ˜¯çœŸæ­£çš„åŒæ­¥ç‚¹ï¼šå¿…é¡»ç­‰å¾…å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ä»»åŠ¡å®Œæˆæ‰èƒ½ç»§ç»­ä¸‹ä¸€æ‰¹
                while len(batch_results) < len(task_indices):
                    try:
                        task_id, success, result_b64, error = self.result_queue.get()
                        
                        # åªå¤„ç†å±äºå½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡ç»“æœ
                        if task_id in expected_task_ids:
                            if success:
                                batch_results[task_id] = _base64_to_image(result_b64)
                            else:
                                print(f"\nâŒ Error editing image {task_id}: {error}")
                                batch_results[task_id] = images[task_id]  # fallback
                            pbar.update(1)
                        else:
                            # å¦‚æœæ”¶åˆ°ä¸å±äºå½“å‰æ‰¹æ¬¡çš„ç»“æœï¼Œè¯´æ˜æœ‰è¿›ç¨‹æå‰å®Œæˆäº†ä»»åŠ¡
                            # è¿™ç§æƒ…å†µä¸åº”è¯¥åœ¨åŒæ­¥æ¨¡å¼ä¸‹å‘ç”Ÿï¼ˆå› ä¸ºä»»åŠ¡æ˜¯æŒ‰æ‰¹æ¬¡æäº¤çš„ï¼‰
                            # ä½†ä¸ºäº†å¥å£®æ€§ï¼Œæˆ‘ä»¬ä»ç„¶å¤„ç†å®ƒï¼Œä½†ä¼šè®°å½•è­¦å‘Š
                            print(f"\nâš ï¸  [SYNC] Received result for task {task_id} outside current batch {expected_task_ids}")
                            # ç›´æ¥å¤„ç†ï¼Œå› ä¸ºtask_idå¯ä»¥æ­£ç¡®åŒ¹é…åˆ°resultsæ•°ç»„
                            if success:
                                results[task_id] = _base64_to_image(result_b64)
                            else:
                                results[task_id] = images[task_id]
                            pbar.update(1)
                    except Exception as e:
                        print(f"\nâŒ Error receiving result: {e}")
                
                # å°†å½“å‰æ‰¹æ¬¡çš„ç»“æœå†™å…¥resultsæ•°ç»„ï¼ˆç¡®ä¿æ‰€æœ‰ç»“æœéƒ½å·²æ”¶é›†ï¼‰
                for task_id in task_indices:
                    if task_id in batch_results:
                        results[task_id] = batch_results[task_id]
                    else:
                        # å¦‚æœæŸä¸ªä»»åŠ¡æ²¡æœ‰ç»“æœï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œä½¿ç”¨åŸå›¾ä½œä¸ºfallback
                        print(f"\nâš ï¸  [SYNC] Missing result for task {task_id} in batch {batch_idx}")
                        results[task_id] = images[task_id]
                
                # å½“å‰æ‰¹æ¬¡å®Œæˆï¼Œæ‰€æœ‰GPUè¿›ç¨‹å·²åŒæ­¥ï¼Œå¯ä»¥å¼€å§‹ä¸‹ä¸€æ‰¹
                if batch_idx < num_batches - 1:
                    pbar.set_postfix_str(f"Batch {batch_idx+1}/{num_batches} done, GPUs synced âœ“")
        
        return results
    
    def _batch_edit_no_sync(self, images, instructions, n, num_gpus, base_seed, **kwargs):
        """
        æ— åŒæ­¥æ¨¡å¼ï¼šä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
        """
        results = [None] * n
        
        print(f"âš¡ No-sync mode (multiprocess): All {n} tasks submitted at once\n")
        
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        for idx in range(n):
            gpu_idx = idx % num_gpus
            current_seed = base_seed + idx
            
            # ç¼–ç å›¾åƒ
            image_b64 = _image_to_base64(images[idx])
            
            # å‘é€ä»»åŠ¡åˆ°å¯¹åº”çš„GPUè¿›ç¨‹
            task = (idx, image_b64, instructions[idx], current_seed, kwargs)
            self.task_queues[gpu_idx].put(task)
        
        # æ”¶é›†ç»“æœï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        with tqdm(total=n, desc="[NO-SYNC] Editing images", unit="img") as pbar:
            for _ in range(n):
                try:
                    task_id, success, result_b64, error = self.result_queue.get()
                    
                    if success:
                        results[task_id] = _base64_to_image(result_b64)
                    else:
                        print(f"\nâŒ Error editing image {task_id}: {error}")
                        results[task_id] = images[task_id]
                except Exception as e:
                    print(f"\nâŒ Error receiving result: {e}")
                finally:
                    pbar.update(1)
        
        return results
    
    def _cleanup_processes(self):
        """
        æ¸…ç†æ‰€æœ‰workerè¿›ç¨‹å’Œé˜Ÿåˆ—
        """
        # åœæ­¢ç»“æœåˆ†å‘çº¿ç¨‹
        if hasattr(self, '_result_dispatcher_thread'):
            self._stop_result_dispatcher()
        
        if not hasattr(self, 'processes'):
            return
        
        print(f"[Flux2Dev] ğŸ§¹ Cleaning up {len(self.processes)} worker processes...")
        
        # å‘æ‰€æœ‰å­˜æ´»çš„è¿›ç¨‹å‘é€åœæ­¢ä¿¡å·
        if hasattr(self, 'task_queues'):
            for task_queue in self.task_queues:
                try:
                    task_queue.put(None)
                except:
                    pass  # é˜Ÿåˆ—å¯èƒ½å·²æŸå
        
        # ç»ˆæ­¢æ‰€æœ‰è¿›ç¨‹
        for gpu_id, p in self.processes:
            if p.is_alive():
                try:
                    p.terminate()
                    p.join(timeout=5)
                    print(f"[Flux2Dev]   âœ… GPU {gpu_id} process terminated")
                except Exception as e:
                    print(f"[Flux2Dev]   âš ï¸  Error terminating GPU {gpu_id} process: {e}")
            else:
                print(f"[Flux2Dev]   âœ“ GPU {gpu_id} process already dead")
        
        # æ¸…ç†é˜Ÿåˆ—ï¼ˆé‡è¦ï¼šé˜²æ­¢é˜Ÿåˆ—å †ç§¯å¯¼è‡´å†…å­˜æ³„æ¼ï¼‰
        if hasattr(self, 'task_queues'):
            for task_queue in self.task_queues:
                # æ¸…ç©ºé˜Ÿåˆ—ä¸­çš„æ‰€æœ‰ä»»åŠ¡
                while not task_queue.empty():
                    try:
                        task_queue.get_nowait()
                    except:
                        break
        
        if hasattr(self, 'result_queue'):
            while not self.result_queue.empty():
                try:
                    self.result_queue.get_nowait()
                except:
                    break
        
        print(f"[Flux2Dev] âœ… Cleanup complete")
    
    def unload_from_gpu(self):
        """
        åœæ­¢æ‰€æœ‰å·¥ä½œè¿›ç¨‹ï¼ˆæ¸…ç†èµ„æºï¼‰
        """
        if not hasattr(self, 'processes') or len(self.processes) == 0:
            print(f"[Flux2Dev] No processes to unload")
            return
        
        print(f"[Flux2Dev] Stopping {len(self.processes)} worker processes...")
        
        # åœæ­¢ç»“æœåˆ†å‘çº¿ç¨‹ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
        if hasattr(self, '_result_dispatcher_thread'):
            self._stop_result_dispatcher()
        
        # å‘æ‰€æœ‰è¿›ç¨‹å‘é€åœæ­¢ä¿¡å·ï¼ˆä¼˜é›…é€€å‡ºï¼‰
        if hasattr(self, 'task_queues'):
            for task_queue in self.task_queues:
                try:
                    task_queue.put(None)
                except:
                    pass  # é˜Ÿåˆ—å¯èƒ½å·²æŸå
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ä¼˜é›…é€€å‡ºï¼ˆæœ€å¤š5ç§’æ¯ä¸ªè¿›ç¨‹ï¼‰
        import time
        start_time = time.time()
        for gpu_id, p in self.processes:
            if not p.is_alive():
                print(f"[Flux2Dev] âœ“ GPU {gpu_id} process already stopped")
                continue
            
            try:
                remaining_time = max(1, 5 - (time.time() - start_time))
                p.join(timeout=remaining_time)
                
                if p.is_alive():
                    print(f"[Flux2Dev] âš ï¸  GPU {gpu_id} process did not terminate gracefully, forcing...")
                    p.terminate()
                    p.join(timeout=3)
                    
                    # å¦‚æœterminateè¿˜ä¸è¡Œï¼Œä½¿ç”¨kill
                    if p.is_alive():
                        print(f"[Flux2Dev] âš ï¸  GPU {gpu_id} process did not respond to SIGTERM, killing...")
                        p.kill()
                        p.join(timeout=2)
                        
                        if p.is_alive():
                            print(f"[Flux2Dev] âŒ GPU {gpu_id} process is unresponsive (zombie)")
                        else:
                            print(f"[Flux2Dev] âœ… GPU {gpu_id} process killed")
                    else:
                        print(f"[Flux2Dev] âœ… GPU {gpu_id} process terminated")
                else:
                    print(f"[Flux2Dev] âœ… GPU {gpu_id} process stopped gracefully")
                    
            except Exception as e:
                print(f"[Flux2Dev] âš ï¸  Error stopping GPU {gpu_id} process: {e}")
        
        # æ¸…ç†é˜Ÿåˆ—ä¸­çš„æ®‹ç•™æ•°æ®ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        if hasattr(self, 'task_queues'):
            for i, task_queue in enumerate(self.task_queues):
                cleared = 0
                while not task_queue.empty():
                    try:
                        task_queue.get_nowait()
                        cleared += 1
                    except:
                        break
                if cleared > 0:
                    print(f"[Flux2Dev] ğŸ§¹ Cleared {cleared} pending tasks from GPU {self.device_ids[i]} queue")
        
        if hasattr(self, 'result_queue'):
            cleared = 0
            while not self.result_queue.empty():
                try:
                    self.result_queue.get_nowait()
                    cleared += 1
                except:
                    break
            if cleared > 0:
                print(f"[Flux2Dev] ğŸ§¹ Cleared {cleared} pending results from result queue")
        
        print(f"[Flux2Dev] âœ… All worker processes stopped")
    
    def load_to_gpu(self, parallel: bool = True):
        """
        å°†æ¨¡å‹åŠ è½½åˆ°GPUï¼ˆé‡æ–°å¯åŠ¨workerè¿›ç¨‹ï¼‰
        
        å¤šè¿›ç¨‹ç‰ˆæœ¬éœ€è¦æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»ï¼Œå¦‚æœè¿›ç¨‹å·²æ­»åˆ™é‡æ–°å¯åŠ¨
        """
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
        if hasattr(self, 'processes') and len(self.processes) > 0:
            alive_processes = [p for _, p in self.processes if p.is_alive()]
            dead_processes = [gpu_id for gpu_id, p in self.processes if not p.is_alive()]
            
            if len(alive_processes) == len(self.processes):
                print(f"[Flux2Dev] âœ… All {len(self.processes)} worker processes are already running")
                return
            else:
                print(f"[Flux2Dev] âš ï¸  Detected {len(dead_processes)} dead processes: {dead_processes}")
                print(f"[Flux2Dev] ğŸ”„ Restarting all worker processes...")
                # æ¸…ç†æ‰€æœ‰è¿›ç¨‹å’Œé˜Ÿåˆ—
                self._cleanup_processes()
        
        # é‡æ–°åˆå§‹åŒ–ï¼ˆå¯åŠ¨æ–°è¿›ç¨‹ï¼‰
        print(f"[Flux2Dev] ğŸš€ Initializing worker processes...")
        self._initialize()
    
    def __del__(self):
        """æ¸…ç†èµ„æºï¼ˆææ„å‡½æ•°ï¼‰"""
        if hasattr(self, 'processes') and len(self.processes) > 0:
            # ç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å·²åœæ­¢ï¼ˆä½¿ç”¨å¼ºåˆ¶æ–¹å¼ï¼‰
            for gpu_id, p in self.processes:
                if p.is_alive():
                    try:
                        # ç›´æ¥terminateï¼Œä¸ç­‰å¾…ä¼˜é›…é€€å‡º
                        p.terminate()
                        p.join(timeout=2)
                        
                        # å¦‚æœè¿˜æ´»ç€ï¼Œå¼ºåˆ¶kill
                        if p.is_alive():
                            p.kill()
                            p.join(timeout=1)
                    except:
                        pass  # ææ„å‡½æ•°ä¸åº”æŠ›å‡ºå¼‚å¸¸
