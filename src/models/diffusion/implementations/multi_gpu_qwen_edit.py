"""
Multi-GPU Qwen-Image-Edit diffusion model implementation
å¤šGPUå¹¶è¡Œçš„Qwenå›¾åƒç¼–è¾‘æ¨¡å‹å®ç°ï¼ˆæ”¯æŒå¤šGPUå¹¶è¡Œ - å¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰

åŸºäºå·²éªŒè¯çš„å¤šGPUä»»åŠ¡åˆ†é…é€»è¾‘
ä½¿ç”¨å¤šè¿›ç¨‹æ¶æ„å®ç°å¤šGPUå¹¶è¡Œ

å¤šè¿›ç¨‹æ¶æ„ï¼š
- æ¯ä¸ªGPUå¯¹åº”ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹
- è¿›ç¨‹é—´å®Œå…¨éš”ç¦»ï¼Œé¿å…GILå’Œèµ„æºç«äº‰
- ä½¿ç”¨Queueè¿›è¡Œè¿›ç¨‹é—´é€šä¿¡
"""

import multiprocessing as mp
import torch
from PIL import Image
from typing import List, Dict, Any
from tqdm import tqdm
import base64
from io import BytesIO
import sys

from ..base_diffusion import BaseDiffusionModel
from ....utils import setup_logger

# å¿…é¡»è®¾ç½®ï¼Œå¦åˆ™å¤šè¿›ç¨‹ä¼šå‡ºé”™
mp.set_start_method('spawn', force=True)


def _load_model_in_process(gpu_id: int, model_name: str, config: Dict[str, Any]):
    """
    åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­åŠ è½½æ¨¡å‹
    
    Args:
        gpu_id: GPU ID
        model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
        config: æ¨¡å‹é…ç½®å‚æ•°
    
    Returns:
        pipelineå¯¹è±¡
    """
    print(f"[GPU {gpu_id}] ğŸ”„ Loading Qwen-Image-Edit model...")
    try:
        from diffusers import QwenImageEditPipeline
        
        # è®¾ç½®å½“å‰è®¾å¤‡
        torch.cuda.set_device(gpu_id)
        
        # æ¸…ç©ºGPUç¼“å­˜
        print(f"[GPU {gpu_id}] ğŸ§¹ Clearing GPU cache...")
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        
        # è§£ædtype
        dtype = config.get("dtype", "bfloat16")
        if dtype == "bfloat16":
            torch_dtype = torch.bfloat16
        elif dtype == "float16":
            torch_dtype = torch.float16
        else:
            torch_dtype = torch.float32
        
        # åŠ è½½æ¨¡å‹ - ä½¿ç”¨low_cpu_mem_usageå‡å°‘å†…å­˜å ç”¨
        print(f"[GPU {gpu_id}] ğŸ”¹ Loading model to cuda:{gpu_id}...")
        pipeline = QwenImageEditPipeline.from_pretrained(
            model_name,
            torch_dtype=torch_dtype,
            low_cpu_mem_usage=True
        )
        
        # ç§»åŠ¨åˆ°ç›®æ ‡GPU
        pipeline.to(f"cuda:{gpu_id}")
        
        # ç¦ç”¨è¿›åº¦æ¡
        if config.get("disable_progress_bar", True):
            pipeline.set_progress_bar_config(disable=True)
        
        print(f"[GPU {gpu_id}] âœ… Model loaded successfully")
        return pipeline
        
    except Exception as e:
        print(f"[GPU {gpu_id}] âŒ Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return None

    
def _image_to_base64(image: Image.Image) -> str:
    """å°†PIL Imageè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
    buffer = BytesIO()
    image.save(buffer, format='PNG')
    return base64.b64encode(buffer.getvalue()).decode('utf-8')


def _base64_to_image(b64_str: str) -> Image.Image:
    """å°†base64å­—ç¬¦ä¸²è½¬æ¢ä¸ºPIL Image"""
    image_data = base64.b64decode(b64_str)
    return Image.open(BytesIO(image_data))


def _process_worker(gpu_id: int, model_name: str, config: Dict[str, Any], 
                    task_queue: mp.Queue, result_queue: mp.Queue):
    """
    è¿›ç¨‹å·¥ä½œå‡½æ•°ï¼šåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­å¤„ç†å›¾åƒç¼–è¾‘ä»»åŠ¡
    
    Args:
        gpu_id: GPU ID
        model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
        config: æ¨¡å‹é…ç½®å‚æ•°
        task_queue: ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ¥æ”¶ä»»åŠ¡ï¼‰
        result_queue: ç»“æœé˜Ÿåˆ—ï¼ˆå‘é€ç»“æœï¼‰
    """
    try:
        # åŠ è½½æ¨¡å‹
        pipeline = _load_model_in_process(gpu_id, model_name, config)
        if pipeline is None:
            print(f"[GPU {gpu_id}] âŒ Failed to load model, exiting...")
            return
        
        # æå–é…ç½®å‚æ•°
        num_inference_steps = config.get("num_inference_steps", 50)
        true_cfg_scale = config.get("true_cfg_scale", 4.0)
        negative_prompt = config.get("negative_prompt", " ")
        seed = config.get("seed", 0)
        
        print(f"[GPU {gpu_id}] âœ… Worker ready, waiting for tasks...")
        
        # å¤„ç†ä»»åŠ¡å¾ªç¯
        while True:
            # ä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡
            task = task_queue.get()
            
            # æ£€æŸ¥ç»“æŸä¿¡å·
            if task is None:
                print(f"[GPU {gpu_id}] ğŸ›‘ Received stop signal, exiting...")
                break
            
            task_id, image_b64, instruction, current_seed, kwargs = task
            
            try:
                # è§£ç å›¾åƒ
                image = _base64_to_image(image_b64)
                
                # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                
                # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è®¾å¤‡
                torch.cuda.set_device(gpu_id)
                
                # å‡†å¤‡å‚æ•°
                num_steps = kwargs.get("num_inference_steps", num_inference_steps)
                cfg_scale = kwargs.get("true_cfg_scale", true_cfg_scale)
                neg_prompt = kwargs.get("negative_prompt", negative_prompt)
                use_seed = current_seed if current_seed is not None else seed
                show_progress = kwargs.get("show_progress", True)  # é»˜è®¤æ˜¾ç¤ºè¿›åº¦æ¡
                
                # å‡†å¤‡pipelineè¾“å…¥
                pipeline_inputs = {
                    "image": image,
                    "prompt": instruction,
                    "generator": torch.Generator(device=f"cuda:{gpu_id}").manual_seed(use_seed),
                    "true_cfg_scale": cfg_scale,
                    "negative_prompt": neg_prompt,
                    "num_inference_steps": num_steps,
                }
                
                # æ·»åŠ å»å™ªè¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                pbar = None
                if show_progress:
                    # ä¸ºæ¯ä¸ªGPUè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„è¿›åº¦æ¡
                    pbar = tqdm(
                        total=num_steps,
                        desc=f"[GPU {gpu_id}] Task {task_id} Denoising",
                        unit="step",
                        leave=False,  # å®Œæˆåæ¸…é™¤ï¼Œé¿å…è¾“å‡ºæ··ä¹±
                        file=sys.stdout,
                        ncols=100,  # é™åˆ¶å®½åº¦ï¼Œé¿å…å¤šè¿›ç¨‹è¾“å‡ºæ—¶æ··ä¹±
                        dynamic_ncols=False,  # å›ºå®šå®½åº¦
                        bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
                    )
                    
                    def callback(pipe, step_index, timestep, callback_kwargs):
                        if pbar is not None:
                            pbar.update(1)
                        return callback_kwargs
                    
                    pipeline_inputs["callback_on_step_end"] = callback
                
                # æ‰§è¡Œæ¨ç†
                try:
                    with torch.inference_mode():
                        output = pipeline(**pipeline_inputs)
                        edited_image = output.images[0]
                finally:
                    # å…³é—­è¿›åº¦æ¡
                    if pbar is not None:
                        pbar.close()
                
                # ç¼–ç ç»“æœå›¾åƒ
                result_b64 = _image_to_base64(edited_image)
                
                # å‘é€ç»“æœ
                result_queue.put((task_id, True, result_b64, None))
                
            except Exception as e:
                print(f"[GPU {gpu_id}] âŒ Error processing task {task_id}: {e}")
                import traceback
                traceback.print_exc()
                # å‘é€é”™è¯¯ç»“æœ
                result_queue.put((task_id, False, None, str(e)))
            
            # æ¸…ç†GPUç¼“å­˜
            torch.cuda.empty_cache()
        
        print(f"[GPU {gpu_id}] ğŸ‘‹ Worker exiting...")
        
    except Exception as e:
        print(f"[GPU {gpu_id}] âŒ Fatal error in worker: {e}")
        import traceback
        traceback.print_exc()
    


class MultiGPUQwenImageEditModel(BaseDiffusionModel):
    """
    å¤šGPUå¹¶è¡Œçš„Qwen-Image-Editæ¨¡å‹ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
    
    ä½¿ç”¨multiprocessingå®ç°æ•°æ®å¹¶è¡Œï¼š
    - æ¯ä¸ªGPUå¯¹åº”ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹
    - æ¯ä¸ªè¿›ç¨‹åŠ è½½ä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬
    - ä»»åŠ¡æŒ‰è½®è¯¢æ–¹å¼åˆ†é…åˆ°å„ä¸ªGPUè¿›ç¨‹
    - æ‰€æœ‰GPUè¿›ç¨‹å¹¶è¡Œå¤„ç†ä¸åŒçš„å›¾åƒ
    
    ç‰¹ç‚¹ï¼š
    - æ”¯æŒå¤šGPUå¹¶è¡Œå¤„ç†
    - æ”¯æŒæ‰¹æ¬¡åŒæ­¥ï¼Œç¡®ä¿GPUé—´è¿›åº¦ä¸€è‡´
    - è¿›ç¨‹é—´å®Œå…¨éš”ç¦»ï¼Œé¿å…GILå’Œèµ„æºç«äº‰
    """
    
    def _initialize(self):
        """åˆå§‹åŒ–å¤šGPUæ¨¡å‹ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰"""
        # è·å–é…ç½®
        self.model_name = self.config.get("model_name", "Qwen/Qwen-Image-Edit")
        device_ids = self.config.get("device_ids", None)
        
        # ç¡®å®šä½¿ç”¨å“ªäº›GPU
        if device_ids is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
            self.num_gpus = torch.cuda.device_count()
            self.device_ids = list(range(self.num_gpus))
        else:
            self.device_ids = device_ids
            self.num_gpus = len(device_ids)
        
        print(f"[MultiGPUQwenImageEdit] æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªGPU")
        print(f"[MultiGPUQwenImageEdit] å°†ä½¿ç”¨ {self.num_gpus} ä¸ªGPU: {self.device_ids}")
        print(f"[MultiGPUQwenImageEdit] ä½¿ç”¨å¤šè¿›ç¨‹æ¶æ„ï¼ˆæ¯ä¸ªGPUä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹ï¼‰\n")
        
        # åˆ›å»ºè¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—
        self.task_queues = [mp.Queue() for _ in range(self.num_gpus)]
        self.result_queue = mp.Queue()
        
        # å¯åŠ¨å·¥ä½œè¿›ç¨‹
        self.processes = []
        print("=" * 70)
        print("ğŸš€ Starting Worker Processes (Qwen-Image-Edit)")
        print("=" * 70)
        print(f"Starting {self.num_gpus} worker processes...")
        print("(Each process will load model independently)")
        print()
        
        for idx, gpu_id in enumerate(self.device_ids):
            print(f"[{idx+1}/{self.num_gpus}] Starting process for GPU {gpu_id}...")
            
            p = mp.Process(
                target=_process_worker,
                args=(
                    gpu_id,
                    self.model_name,
                    self.config,
                    self.task_queues[idx],
                    self.result_queue
                ),
                name=f"GPU-{gpu_id}"
            )
            p.start()
            self.processes.append((gpu_id, p))
            print(f"  âœ… GPU {gpu_id}: Process started (PID: {p.pid})\n")
        
        print(f"âœ… Successfully started {len(self.processes)} worker processes")
        print(f"  âš¡ All processes are loading models independently")
        print("=" * 70)
        print()
    
    def edit_image(self, original_image: Image.Image, 
                   edit_instruction: str,
                   **kwargs) -> Image.Image:
        """
        ç¼–è¾‘å•å¼ å›¾åƒï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªGPUè¿›ç¨‹ï¼‰
        
        Args:
            original_image: åŸå§‹PILå›¾åƒ
            edit_instruction: ç¼–è¾‘æŒ‡ä»¤
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç¼–è¾‘åçš„PILå›¾åƒ
        """
        # å•å¼ å›¾åƒä½¿ç”¨ç¬¬ä¸€ä¸ªGPUè¿›ç¨‹
        results = self.batch_edit([original_image], [edit_instruction], **kwargs)
        return results[0]
    
    def batch_edit(self, images: List[Image.Image],
                   instructions: List[str],
                   **kwargs) -> List[Image.Image]:
        """
        å¤šGPUå¹¶è¡Œæ‰¹é‡ç¼–è¾‘å›¾åƒï¼ˆå¸¦æ‰¹æ¬¡åŒæ­¥ï¼‰
        
        å®ç°æ‰¹æ¬¡åŒæ­¥æœºåˆ¶ï¼š
        - å°†ä»»åŠ¡åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹å¤§å° = GPUæ•°é‡
        - æ¯æ‰¹ä»»åŠ¡æäº¤åï¼Œç­‰å¾…æ‰€æœ‰GPUå®Œæˆ
        - å†æäº¤ä¸‹ä¸€æ‰¹ï¼Œç¡®ä¿GPUä¹‹é—´ä¿æŒåŒæ­¥
        
        Args:
            images: åŸå§‹å›¾åƒåˆ—è¡¨
            instructions: ç¼–è¾‘æŒ‡ä»¤åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
                - enable_batch_sync: æ˜¯å¦å¯ç”¨æ‰¹æ¬¡åŒæ­¥ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            ç¼–è¾‘åçš„å›¾åƒåˆ—è¡¨
        """
        if len(images) != len(instructions):
            raise ValueError("Number of images must match number of instructions")
        
        n = len(images)
        num_gpus = self.num_gpus  # ä½¿ç”¨è¿›ç¨‹æ•°é‡è€Œä¸æ˜¯workersæ•°é‡
        enable_sync = kwargs.pop("enable_batch_sync", True)  # é»˜è®¤å¯ç”¨æ‰¹æ¬¡åŒæ­¥
        
        print(f"\n[MultiGPUQwenImageEdit] Starting batch edit: {n} images on {num_gpus} GPUs")
        print(f"  ğŸ”„ Batch synchronization: {'ENABLED âœ…' if enable_sync else 'DISABLED âš ï¸'}")
        
        # é¢„å…ˆåˆ†é…ä»»åŠ¡å¹¶æ˜¾ç¤º
        print("=" * 70)
        print("ğŸ“‹ Task Assignment:")
        print("=" * 70)
        from collections import defaultdict
        gpu_assignments = defaultdict(list)
        
        for idx in range(n):
            gpu_id = self.device_ids[idx % num_gpus]
            gpu_assignments[gpu_id].append(idx)
        
        for gpu_id in sorted(gpu_assignments.keys()):
            assigned = gpu_assignments[gpu_id]
            print(f"  GPU {gpu_id}: {len(assigned)} images")
            preview = ", ".join(map(str, assigned[:5]))
            if len(assigned) > 5:
                preview += f", ... +{len(assigned) - 5} more"
            print(f"           â†’ [{preview}]")
        
        print("=" * 70)
        print()
        
        # ç»“æœåˆ—è¡¨ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
        results = [None] * n
        
        # è·å–åŸºç¡€seed
        base_seed = kwargs.get("seed", self.config.get("seed", 0))
        
        if enable_sync:
            # æ‰¹æ¬¡åŒæ­¥æ¨¡å¼ï¼šæ¯æ‰¹num_gpusä¸ªä»»åŠ¡ï¼Œæ‰¹æ¬¡é—´åŒæ­¥
            results = self._batch_edit_with_sync(
                images, instructions, n, num_gpus, base_seed, **kwargs
            )
        else:
            # åŸå§‹æ¨¡å¼ï¼šä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå‘åå…¼å®¹ï¼‰
            results = self._batch_edit_no_sync(
                images, instructions, n, num_gpus, base_seed, **kwargs
            )
        
        print(f"âœ… Batch edit completed: {n} images\n")
        return results
    
    def _batch_edit_with_sync(self, images, instructions, n, num_gpus, base_seed, **kwargs):
        """
        æ‰¹æ¬¡åŒæ­¥æ¨¡å¼ï¼šç¡®ä¿æ¯æ‰¹æ‰€æœ‰GPUå®Œæˆåå†å¼€å§‹ä¸‹ä¸€æ‰¹ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
        """
        results = [None] * n
        
        # è®¡ç®—æ‰¹æ¬¡æ•°
        num_batches = (n + num_gpus - 1) // num_gpus
        
        print(f"ğŸ”„ Batch synchronization mode (multiprocess):")
        print(f"   - Total batches: {num_batches}")
        print(f"   - Batch size: {num_gpus} (one task per GPU process)")
        print(f"   - All GPU processes will stay synchronized at batch boundaries\n")
        
            # æ€»è¿›åº¦æ¡
            with tqdm(total=n, desc="[SYNC] Editing images", unit="img") as pbar:
                # é€æ‰¹å¤„ç†
                for batch_idx in range(num_batches):
                    batch_start = batch_idx * num_gpus
                    batch_end = min(batch_start + num_gpus, n)
                    batch_size = batch_end - batch_start
                    
                # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡
                task_indices = []
                    for i in range(batch_start, batch_end):
                    # ä½¿ç”¨å…¨å±€è½®è¯¢åˆ†é…ï¼ši % num_gpus ç¡®ä¿æ‰€æœ‰ä»»åŠ¡æŒ‰é¡ºåºè½®è¯¢åˆ†é…åˆ°ä¸åŒGPU
                    gpu_idx = i % num_gpus
                        current_seed = base_seed + i
                        
                    # ç¼–ç å›¾åƒ
                    image_b64 = _image_to_base64(images[i])
                    
                    # å‘é€ä»»åŠ¡åˆ°å¯¹åº”çš„GPUè¿›ç¨‹
                    task = (i, image_b64, instructions[i], current_seed, kwargs)
                    self.task_queues[gpu_idx].put(task)
                    task_indices.append(i)
                    
                    # ç­‰å¾…å½“å‰æ‰¹æ¬¡æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆåŒæ­¥ç‚¹ï¼‰
                # ä½¿ç”¨å­—å…¸è·Ÿè¸ªå½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡ï¼Œç¡®ä¿åªæ”¶é›†å½“å‰æ‰¹æ¬¡çš„ç»“æœ
                batch_results = {}
                expected_task_ids = set(task_indices)
                
                # ç­‰å¾…ç›´åˆ°æ”¶é›†åˆ°å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ç»“æœ
                # è¿™æ˜¯çœŸæ­£çš„åŒæ­¥ç‚¹ï¼šå¿…é¡»ç­‰å¾…å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ä»»åŠ¡å®Œæˆæ‰èƒ½ç»§ç»­ä¸‹ä¸€æ‰¹
                while len(batch_results) < len(task_indices):
                        try:
                        task_id, success, result_b64, error = self.result_queue.get()
                        
                        # åªå¤„ç†å±äºå½“å‰æ‰¹æ¬¡çš„ä»»åŠ¡ç»“æœ
                        if task_id in expected_task_ids:
                            if success:
                                batch_results[task_id] = _base64_to_image(result_b64)
                            else:
                                print(f"\nâŒ Error editing image {task_id}: {error}")
                                batch_results[task_id] = images[task_id]  # fallback
                            pbar.update(1)
                        else:
                            # å¦‚æœæ”¶åˆ°ä¸å±äºå½“å‰æ‰¹æ¬¡çš„ç»“æœï¼Œè¯´æ˜æœ‰è¿›ç¨‹æå‰å®Œæˆäº†ä»»åŠ¡
                            # è¿™ç§æƒ…å†µä¸åº”è¯¥åœ¨åŒæ­¥æ¨¡å¼ä¸‹å‘ç”Ÿï¼ˆå› ä¸ºä»»åŠ¡æ˜¯æŒ‰æ‰¹æ¬¡æäº¤çš„ï¼‰
                            # ä½†ä¸ºäº†å¥å£®æ€§ï¼Œæˆ‘ä»¬ä»ç„¶å¤„ç†å®ƒï¼Œä½†ä¼šè®°å½•è­¦å‘Š
                            print(f"\nâš ï¸  [SYNC] Received result for task {task_id} outside current batch {expected_task_ids}")
                            # ç›´æ¥å¤„ç†ï¼Œå› ä¸ºtask_idå¯ä»¥æ­£ç¡®åŒ¹é…åˆ°resultsæ•°ç»„
                            if success:
                                results[task_id] = _base64_to_image(result_b64)
                            else:
                                results[task_id] = images[task_id]
                            pbar.update(1)
                    except Exception as e:
                        print(f"\nâŒ Error receiving result: {e}")
                
                # å°†å½“å‰æ‰¹æ¬¡çš„ç»“æœå†™å…¥resultsæ•°ç»„ï¼ˆç¡®ä¿æ‰€æœ‰ç»“æœéƒ½å·²æ”¶é›†ï¼‰
                for task_id in task_indices:
                    if task_id in batch_results:
                        results[task_id] = batch_results[task_id]
                    else:
                        # å¦‚æœæŸä¸ªä»»åŠ¡æ²¡æœ‰ç»“æœï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œä½¿ç”¨åŸå›¾ä½œä¸ºfallback
                        print(f"\nâš ï¸  [SYNC] Missing result for task {task_id} in batch {batch_idx}")
                        results[task_id] = images[task_id]
                    
                # å½“å‰æ‰¹æ¬¡å®Œæˆï¼Œæ‰€æœ‰GPUè¿›ç¨‹å·²åŒæ­¥ï¼Œå¯ä»¥å¼€å§‹ä¸‹ä¸€æ‰¹
                    if batch_idx < num_batches - 1:
                        pbar.set_postfix_str(f"Batch {batch_idx+1}/{num_batches} done, GPUs synced âœ“")
        
        return results
    
    def _batch_edit_no_sync(self, images, instructions, n, num_gpus, base_seed, **kwargs):
        """
        æ— åŒæ­¥æ¨¡å¼ï¼šä¸€æ¬¡æ€§æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
        """
        results = [None] * n
        
        print(f"âš¡ No-sync mode (multiprocess): All {n} tasks submitted at once\n")
        
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            for idx in range(n):
            gpu_idx = idx % num_gpus
                current_seed = base_seed + idx
                
            # ç¼–ç å›¾åƒ
            image_b64 = _image_to_base64(images[idx])
            
            # å‘é€ä»»åŠ¡åˆ°å¯¹åº”çš„GPUè¿›ç¨‹
            task = (idx, image_b64, instructions[idx], current_seed, kwargs)
            self.task_queues[gpu_idx].put(task)
            
            # æ”¶é›†ç»“æœï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
            with tqdm(total=n, desc="[NO-SYNC] Editing images", unit="img") as pbar:
            for _ in range(n):
                try:
                    task_id, success, result_b64, error = self.result_queue.get()
                    
                    if success:
                        results[task_id] = _base64_to_image(result_b64)
                    else:
                        print(f"\nâŒ Error editing image {task_id}: {error}")
                        results[task_id] = images[task_id]
                    except Exception as e:
                    print(f"\nâŒ Error receiving result: {e}")
                    finally:
                        pbar.update(1)
        
        return results
    
    def unload_from_gpu(self):
        """
        åœæ­¢æ‰€æœ‰å·¥ä½œè¿›ç¨‹ï¼ˆæ¸…ç†èµ„æºï¼‰
        """
        print(f"[MultiGPUQwenImageEdit] Stopping {len(self.processes)} worker processes...")
        
        # å‘æ‰€æœ‰è¿›ç¨‹å‘é€åœæ­¢ä¿¡å·
        for task_queue in self.task_queues:
            task_queue.put(None)
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
        for gpu_id, p in self.processes:
            try:
                p.join(timeout=30)  # æœ€å¤šç­‰å¾…30ç§’
                if p.is_alive():
                    print(f"[MultiGPUQwenImageEdit] âš ï¸  Process for GPU {gpu_id} did not terminate, forcing...")
                    p.terminate()
                    p.join()
                print(f"[MultiGPUQwenImageEdit] âœ… Process for GPU {gpu_id} stopped")
                except Exception as e:
                print(f"[MultiGPUQwenImageEdit] âš ï¸  Error stopping process for GPU {gpu_id}: {e}")
        
        print(f"[MultiGPUQwenImageEdit] All worker processes stopped")
    
    def load_to_gpu(self, parallel: bool = True):
        """
        å°†æ¨¡å‹åŠ è½½åˆ°GPU
        å¤šè¿›ç¨‹ç‰ˆæœ¬ä¸­ï¼Œæ¯ä¸ªè¿›ç¨‹åœ¨å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹
        """
        print(f"[MultiGPUQwenImageEdit] Models are loaded automatically in each process")
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'processes'):
            # ç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å·²åœæ­¢
            for gpu_id, p in self.processes:
                if p.is_alive():
                    try:
                        p.terminate()
                        p.join(timeout=5)
                    except:
                        pass
